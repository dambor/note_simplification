8.2%).\",\n",
    "                \"simplified\": \"You have Type 2 Diabetes with an HbA1c of 8.2%, indicating poor glycemic control over the past 3 months.\"\n",
    "            },\n",
    "            {\n",
    "                \"note\": \"Exhibits peripheral edema and occasional dyspnea on exertion.\",\n",
    "                \"simplified\": \"You're experiencing fluid retention in your extremities and shortness of breath during physical activity.\"\n",
    "            }\n",
    "        ],\n",
    "        \"graduate\": [\n",
    "            {\n",
    "                \"note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c 8.2%).\",\n",
    "                \"simplified\": \"You have Type 2 Diabetes Mellitus with an elevated HbA1c of 8.2%, indicating sustained hyperglycemia over the preceding three months.\"\n",
    "            },\n",
    "            {\n",
    "                \"note\": \"Exhibits peripheral edema and occasional dyspnea on exertion.\",\n",
    "                \"simplified\": \"You're presenting with peripheral edema and intermittent dyspnea upon exertion, suggesting possible cardiovascular or pulmonary etiology.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Default to high_school level if the specified level is not available\n",
    "    if education_level not in examples:\n",
    "        education_level = \"high_school\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Please simplify the following medical note for a patient with {education_level} education level.\n",
    "    \n",
    "    Here are some examples of simplifying medical notes for someone with {education_level} education:\n",
    "    \n",
    "    Original: {examples[education_level][0]['note']}\n",
    "    Simplified: {examples[education_level][0]['simplified']}\n",
    "    \n",
    "    Original: {examples[education_level][1]['note']}\n",
    "    Simplified: {examples[education_level][1]['simplified']}\n",
    "    \n",
    "    Now, I'll simplify this medical note by following a tree-of-thought approach:\n",
    "    \n",
    "    Medical note: {medical_note}\n",
    "    \n",
    "    Let me consider different approaches to simplify this note:\n",
    "    \n",
    "    Approach 1: Replace technical terms with common language appropriate for {education_level} education level\n",
    "    Approach 2: Reorganize information by importance for the patient\n",
    "    Approach 3: Use appropriate formatting and structure to enhance understanding\n",
    "    \n",
    "    Now, combining these approaches for optimal comprehension:\n",
    "    \n",
    "    Final simplified version:\n",
    "    \"\"\"\n",
    "    \n",
    "    return simulate_llm_response(prompt, method=\"combined\", education_level=education_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply combined method to sample data\n",
    "combined_results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    medical_note = row['medical_note']\n",
    "    education_level = row['education_level']\n",
    "    patient_id = row['patient_id']\n",
    "    \n",
    "    # Apply combined method\n",
    "    combined_result = combined_prompt(medical_note, education_level)\n",
    "    combined_complexity = measure_complexity(combined_result)\n",
    "    \n",
    "    combined_results.append({\n",
    "        \"patient_id\": patient_id,\n",
    "        \"education_level\": education_level,\n",
    "        \"original_note\": medical_note,\n",
    "        \"original_complexity\": results[idx]['original_complexity'],\n",
    "        \"combined_result\": combined_result,\n",
    "        \"combined_complexity\": combined_complexity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_combined_method():\n",
    "    \"\"\"Compare the combined method with previous methods.\"\"\"\n",
    "    # Prepare data for comparison\n",
    "    readability_scores = {\n",
    "        'Original': [r['original_complexity']['flesch_kincaid'] for r in results],\n",
    "        'Basic': [r['basic_complexity']['flesch_kincaid'] for r in results],\n",
    "        'In-Context': [r['in_context_complexity']['flesch_kincaid'] for r in results],\n",
    "        'Chain-of-Thought': [r['cot_complexity']['flesch_kincaid'] for r in results],\n",
    "        'Tree-of-Thought': [r['tot_complexity']['flesch_kincaid'] for r in results],\n",
    "        'Combined': [r['combined_complexity']['flesch_kincaid'] for r in combined_results]\n",
    "    }\n",
    "    \n",
    "    medical_terms = {\n",
    "        'Original': [r['original_complexity']['medical_terms_pct'] for r in results],\n",
    "        'Basic': [r['basic_complexity']['medical_terms_pct'] for r in results],\n",
    "        'In-Context': [r['in_context_complexity']['medical_terms_pct'] for r in results],\n",
    "        'Chain-of-Thought': [r['cot_complexity']['medical_terms_pct'] for r in results],\n",
    "        'Tree-of-Thought': [r['tot_complexity']['medical_terms_pct'] for r in results],\n",
    "        'Combined': [r['combined_complexity']['medical_terms_pct'] for r in combined_results]\n",
    "    }\n",
    "    \n",
    "    # Calculate average scores\n",
    "    avg_readability = {method: np.mean(scores) for method, scores in readability_scores.items()}\n",
    "    avg_med_terms = {method: np.mean(scores) for method, scores in medical_terms.items()}\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    methods = list(avg_readability.keys())\n",
    "    x = np.arange(len(methods))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.bar(x - width/2, list(avg_readability.values()), width, label='Readability Score (higher is better)')\n",
    "    ax.bar(x + width/2, list(avg_med_terms.values()), width, label='Medical Terms % (lower is better)')\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(methods)\n",
    "    ax.legend()\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Comparison of All Methods')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('all_methods_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display improvement for combined method\n",
    "    orig_readability = avg_readability['Original']\n",
    "    combined_improvement = avg_readability['Combined'] - orig_readability\n",
    "    best_prev_method = max(avg_readability['Basic'], avg_readability['In-Context'], \n",
    "                          avg_readability['Chain-of-Thought'], avg_readability['Tree-of-Thought'])\n",
    "    best_prev_improvement = best_prev_method - orig_readability\n",
    "    \n",
    "    print(f\"Combined method readability improvement: {combined_improvement:.2f}\")\n",
    "    print(f\"Best previous method improvement: {best_prev_improvement:.2f}\")\n",
    "    print(f\"Additional improvement from combined method: {combined_improvement - best_prev_improvement:.2f}\")\n",
    "    \n",
    "    return avg_readability, avg_med_terms\n",
    "\n",
    "# Compare combined method\n",
    "avg_readability, avg_med_terms = compare_combined_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_combined_sample(patient_id=\"P001\"):\n",
    "    \"\"\"Display a sample of the combined method results.\"\"\"\n",
    "    # Find the result for the specified patient\n",
    "    combined_result = next((r for r in combined_results if r['patient_id'] == patient_id), None)\n",
    "    original_result = next((r for r in results if r['patient_id'] == patient_id), None)\n",
    "    \n",
    "    if combined_result and original_result:\n",
    "        print(f\"Comparison for Patient {patient_id} (Education level: {combined_result['education_level']})\")\n",
    "        print(\"\\nORIGINAL NOTE:\")\n",
    "        print(combined_result['original_note'])\n",
    "        print(f\"\\nReadability score: {combined_result['original_complexity']['flesch_kincaid']:.1f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        \n",
    "        print(\"BEST PREVIOUS METHOD (Tree-of-Thought):\")\n",
    "        print(original_result['tree_of_thought_result'])\n",
    "        print(f\"\\nReadability score: {original_result['tot_complexity']['flesch_kincaid']:.1f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        \n",
    "        print(\"COMBINED METHOD:\")\n",
    "        print(combined_result['combined_result'])\n",
    "        print(f\"\\nReadability score: {combined_result['combined_complexity']['flesch_kincaid']:.1f}\")\n",
    "    else:\n",
    "        print(f\"No results found for patient {patient_id}\")\n",
    "\n",
    "# Display combined method sample\n",
    "display_combined_sample(\"P001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Conclusion:\n",
    "-----------\n",
    "This tutorial has demonstrated the application of various LLM prompting techniques\n",
    "for medical notes simplification. We explored basic prompting, in-context learning,\n",
    "chain-of-thought reasoning, tree-of-thought reasoning, and a combined approach.\n",
    "\n",
    "Key findings:\n",
    "1. All prompting methods improved readability compared to original medical notes\n",
    "2. Tree-of-thought reasoning provided the best structure and organization\n",
    "3. In-context learning was most effective at adapting to different education levels\n",
    "4. The combined approach leveraged the strengths of both methods for superior results\n",
    "\n",
    "Future work:\n",
    "------------\n",
    "1. Test with a larger and more diverse dataset of medical notes\n",
    "2. Implement real LLM API calls instead of simulated responses\n",
    "3. Create a user interface for healthcare providers to use this system\n",
    "4. Evaluate with actual patients from different education backgrounds\n",
    "5. Integrate medical ontologies for better term recognition and replacement\n",
    "6. Explore multi-modal approaches (adding visual elements to explanations)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results and Display Final Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV for further analysis\n",
    "results_df = pd.DataFrame({\n",
    "    'patient_id': [r['patient_id'] for r in results],\n",
    "    'education_level': [r['education_level'] for r in results],\n",
    "    'original_readability': [r['original_complexity']['flesch_kincaid'] for r in results],\n",
    "    'basic_readability': [r['basic_complexity']['flesch_kincaid'] for r in results],\n",
    "    'in_context_readability': [r['in_context_complexity']['flesch_kincaid'] for r in results],\n",
    "    'cot_readability': [r['cot_complexity']['flesch_kincaid'] for r in results],\n",
    "    'tot_readability': [r['tot_complexity']['flesch_kincaid'] for r in results],\n",
    "    'combined_readability': [r['combined_complexity']['flesch_kincaid'] for r in combined_results]\n",
    "})\n",
    "\n",
    "results_df.to_csv('medical_notes_simplification_results.csv', index=False)\n",
    "print(\"Results exported to medical_notes_simplification_results.csv\")\n",
    "\n",
    "# Display final statistics\n",
    "print(\"\\nFinal Statistics:\")\n",
    "print(f\"Average readability improvement: {np.mean(list(avg_readability.values())[1:]) - avg_readability['Original']:.2f}\")\n",
    "print(f\"Best method: Combined (improvement: {avg_readability['Combined'] - avg_readability['Original']:.2f})\")\n",
    "print(f\"Medical terminology reduction: {avg_med_terms['Original'] - avg_med_terms['Combined']:.2f}%\")\n",
    "\n",
    "print(\"\\nTutorial complete! This notebook demonstrates how to use LLMs for medical notes simplification.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}            \"YOUR CONDITION:\": [],\n",
    "            \"YOUR TREATMENT PLAN:\": [],\n",
    "            \"WHAT TO WATCH FOR:\": [],\n",
    "            \"NEXT STEPS:\": []\n",
    "        }\n",
    "        \n",
    "        # Populate sections with education-level appropriate content\n",
    "        if \"high blood pressure\" in simplified or \"blood pressure\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You have high blood pressure\")\n",
    "        if \"heart attack\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You had a heart attack in the past\")\n",
    "        if \"diabetes\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You have diabetes\")\n",
    "        if \"infection\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You have an infection\")\n",
    "        if \"acid reflux\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You have acid reflux (heartburn)\")\n",
    "        if \"migraine\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You get migraine headaches\")\n",
    "            \n",
    "        if \"medicine\" in simplified:\n",
    "            meds = re.findall(r'([a-zA-Z]+) (medicine|medication)', simplified)\n",
    "            for med in meds:\n",
    "                sections[\"YOUR TREATMENT PLAN:\"].append(f\"Take your {med[0]} {med[1]} as prescribed\")\n",
    "        \n",
    "        if \"diet\" in simplified:\n",
    "            sections[\"YOUR TREATMENT PLAN:\"].append(\"Follow the recommended diet plan\")\n",
    "        if \"exercise\" in simplified:\n",
    "            sections[\"YOUR TREATMENT PLAN:\"].append(\"Exercise regularly as recommended\")\n",
    "            \n",
    "        sections[\"NEXT STEPS:\"].append(\"Follow up with your doctor as scheduled\")\n",
    "        sections[\"NEXT STEPS:\"].append(\"Call if your symptoms get worse or you have questions\")\n",
    "        \n",
    "        # Format the results with more emphasis on education level\n",
    "        result = f\"SIMPLIFIED MEDICAL NOTE (FOR {education_level.upper()} EDUCATION LEVEL):\\n\\n\"\n",
    "        for section, items in sections.items():\n",
    "            if items:  # Only include non-empty sections\n",
    "                result += section + \"\\n\"\n",
    "                for item in items:\n",
    "                    result += f\"- {item}\\n\"\n",
    "                result += \"\\n\"\n",
    "                \n",
    "        simplified = result\n",
    "\n",
    "    return simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data with Different Prompting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the sample data with different methods\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    medical_note = row['medical_note']\n",
    "    education_level = row['education_level']\n",
    "    patient_id = row['patient_id']\n",
    "    \n",
    "    # Apply different prompting methods\n",
    "    basic_result = basic_prompt(medical_note)\n",
    "    in_context_result = in_context_learning_prompt(medical_note, education_level)\n",
    "    cot_result = chain_of_thought_prompt(medical_note, education_level)\n",
    "    tot_result = tree_of_thought_prompt(medical_note, education_level)\n",
    "    \n",
    "    # Measure complexity of original and simplified notes\n",
    "    original_complexity = measure_complexity(medical_note)\n",
    "    basic_complexity = measure_complexity(basic_result)\n",
    "    in_context_complexity = measure_complexity(in_context_result)\n",
    "    cot_complexity = measure_complexity(cot_result)\n",
    "    tot_complexity = measure_complexity(tot_result)\n",
    "    \n",
    "    results.append({\n",
    "        \"patient_id\": patient_id,\n",
    "        \"education_level\": education_level,\n",
    "        \"original_note\": medical_note,\n",
    "        \"original_complexity\": original_complexity,\n",
    "        \"basic_prompt_result\": basic_result,\n",
    "        \"basic_complexity\": basic_complexity,\n",
    "        \"in_context_result\": in_context_result,\n",
    "        \"in_context_complexity\": in_context_complexity,\n",
    "        \"chain_of_thought_result\": cot_result,\n",
    "        \"cot_complexity\": cot_complexity,\n",
    "        \"tree_of_thought_result\": tot_result,\n",
    "        \"tot_complexity\": tot_complexity\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_readability_comparisons(results_df):\n",
    "    \"\"\"Create visualizations comparing readability metrics across different methods.\"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Extract Flesch-Kincaid scores for all methods\n",
    "    fk_scores = {\n",
    "        'Original': [r['original_complexity']['flesch_kincaid'] for r in results],\n",
    "        'Basic': [r['basic_complexity']['flesch_kincaid'] for r in results],\n",
    "        'In-Context': [r['in_context_complexity']['flesch_kincaid'] for r in results],\n",
    "        'Chain-of-Thought': [r['cot_complexity']['flesch_kincaid'] for r in results],\n",
    "        'Tree-of-Thought': [r['tot_complexity']['flesch_kincaid'] for r in results]\n",
    "    }\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    methods = list(fk_scores.keys())\n",
    "    x = np.arange(len(results))\n",
    "    width = 0.15\n",
    "    offsets = np.arange(-2, 3) * width\n",
    "    \n",
    "    # Plot bars for each method\n",
    "    for i, method in enumerate(methods):\n",
    "        plt.bar(x + offsets[i], fk_scores[method], width, label=method)\n",
    "    \n",
    "    plt.xlabel('Patient')\n",
    "    plt.ylabel('Flesch-Kincaid Readability (higher is better)')\n",
    "    plt.title('Readability Comparison Across Methods')\n",
    "    plt.xticks(x, [r['patient_id'] for r in results])\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add horizontal lines for readability guidelines\n",
    "    plt.axhline(y=80, color='g', linestyle='-', alpha=0.3)\n",
    "    plt.axhline(y=60, color='y', linestyle='-', alpha=0.3)\n",
    "    plt.axhline(y=40, color='r', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    plt.text(len(results)-1, 85, 'Easy', color='g', ha='right')\n",
    "    plt.text(len(results)-1, 65, 'Standard', color='y', ha='right')\n",
    "    plt.text(len(results)-1, 45, 'Difficult', color='r', ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('readability_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot average sentence length comparison\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Extract average sentence lengths\n",
    "    sent_lengths = {\n",
    "        'Original': [r['original_complexity']['avg_sentence_length'] for r in results],\n",
    "        'Basic': [r['basic_complexity']['avg_sentence_length'] for r in results],\n",
    "        'In-Context': [r['in_context_complexity']['avg_sentence_length'] for r in results],\n",
    "        'Chain-of-Thought': [r['cot_complexity']['avg_sentence_length'] for r in results],\n",
    "        'Tree-of-Thought': [r['tot_complexity']['avg_sentence_length'] for r in results]\n",
    "    }\n",
    "    \n",
    "    # Plot bars for each method\n",
    "    for i, method in enumerate(methods):\n",
    "        plt.bar(x + offsets[i], sent_lengths[method], width, label=method)\n",
    "    \n",
    "    plt.xlabel('Patient')\n",
    "    plt.ylabel('Average Sentence Length (words)')\n",
    "    plt.title('Sentence Length Comparison Across Methods')\n",
    "    plt.xticks(x, [r['patient_id'] for r in results])\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add reference line for recommended sentence length\n",
    "    plt.axhline(y=15, color='r', linestyle='--', alpha=0.5)\n",
    "    plt.text(len(results)-1, 16, 'Recommended max. for general audience', color='r', ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sentence_length_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Compare medical terms percentage\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Extract medical terms percentages\n",
    "    med_terms = {\n",
    "        'Original': [r['original_complexity']['medical_terms_pct'] for r in results],\n",
    "        'Basic': [r['basic_complexity']['medical_terms_pct'] for r in results],\n",
    "        'In-Context': [r['in_context_complexity']['medical_terms_pct'] for r in results],\n",
    "        'Chain-of-Thought': [r['cot_complexity']['medical_terms_pct'] for r in results],\n",
    "        'Tree-of-Thought': [r['tot_complexity']['medical_terms_pct'] for r in results]\n",
    "    }\n",
    "    \n",
    "    # Plot bars for each method\n",
    "    for i, method in enumerate(methods):\n",
    "        plt.bar(x + offsets[i], med_terms[method], width, label=method)\n",
    "    \n",
    "    plt.xlabel('Patient')\n",
    "    plt.ylabel('Medical Terms (%)')\n",
    "    plt.title('Medical Terminology Usage Across Methods')\n",
    "    plt.xticks(x, [r['patient_id'] for r in results])\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('medical_terms_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "# Run the plotting function\n",
    "plot_readability_comparisons(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze by Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_by_education_level(results_df):\n",
    "    \"\"\"Analyze the effectiveness of different methods by education level.\"\"\"\n",
    "    # Group by education level\n",
    "    education_levels = results_df['education_level'].unique()\n",
    "    \n",
    "    # Calculate average readability improvements by education level and method\n",
    "    improvements = []\n",
    "    \n",
    "    for edu in education_levels:\n",
    "        edu_rows = results_df[results_df['education_level'] == edu]\n",
    "        \n",
    "        for _, row in edu_rows.iterrows():\n",
    "            orig_fk = row['original_complexity']['flesch_kincaid']\n",
    "            \n",
    "            # Calculate improvements for each method\n",
    "            basic_imp = row['basic_complexity']['flesch_kincaid'] - orig_fk\n",
    "            in_context_imp = row['in_context_complexity']['flesch_kincaid'] - orig_fk\n",
    "            cot_imp = row['cot_complexity']['flesch_kincaid'] - orig_fk\n",
    "            tot_imp = row['tot_complexity']['flesch_kincaid'] - orig_fk\n",
    "            \n",
    "            improvements.append({\n",
    "                'education_level': edu,\n",
    "                'basic_improvement': basic_imp,\n",
    "                'in_context_improvement': in_context_imp,\n",
    "                'cot_improvement': cot_imp,\n",
    "                'tot_improvement': tot_imp\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    imp_df = pd.DataFrame(improvements)\n",
    "    \n",
    "    # Group by education level and calculate mean improvements\n",
    "    grouped = imp_df.groupby('education_level').mean()\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    grouped.plot(kind='bar', figsize=(12, 6))\n",
    "    plt.title('Average Readability Improvement by Education Level')\n",
    "    plt.ylabel('Flesch-Kincaid Score Improvement')\n",
    "    plt.xlabel('Education Level')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('improvement_by_education.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "# Run education level analysis\n",
    "education_analysis = analyze_by_education_level(results_df)\n",
    "print(\"Average readability improvement by education level:\")\n",
    "print(education_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_comparison(results_df, patient_id=\"P001\"):\n",
    "    \"\"\"Display a side-by-side comparison of original and simplified notes.\"\"\"\n",
    "    row = results_df[results_df['patient_id'] == patient_id].iloc[0]\n",
    "    \n",
    "    print(f\"Comparison for Patient {patient_id} (Education level: {row['education_level']})\")\n",
    "    print(\"\\nORIGINAL NOTE:\")\n",
    "    print(row['original_note'])\n",
    "    print(f\"\\nReadability score: {row['original_complexity']['flesch_kincaid']:.1f}\")\n",
    "    print(f\"Average sentence length: {row['original_complexity']['avg_sentence_length']:.1f} words\")\n",
    "    print(f\"Medical terms: {row['original_complexity']['medical_terms_pct']:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\"TREE-OF-THOUGHT SIMPLIFIED NOTE:\")\n",
    "    print(row['tree_of_thought_result'])\n",
    "    print(f\"\\nReadability score: {row['tot_complexity']['flesch_kincaid']:.1f}\")\n",
    "    print(f\"Average sentence length: {row['tot_complexity']['avg_sentence_length']:.1f} words\")\n",
    "    print(f\"Medical terms: {row['tot_complexity']['medical_terms_pct']:.1f}%\")\n",
    "\n",
    "# Display sample comparison\n",
    "display_sample_comparison(results_df, \"P001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_methods():\n",
    "    \"\"\"Evaluate the different methods using common metrics.\"\"\"\n",
    "    # Calculate average improvements across all patients\n",
    "    avg_improvements = {\n",
    "        'Basic': np.mean([r['basic_complexity']['flesch_kincaid'] - r['original_complexity']['flesch_kincaid'] for r in results]),\n",
    "        'In-Context': np.mean([r['in_context_complexity']['flesch_kincaid'] - r['original_complexity']['flesch_kincaid'] for r in results]),\n",
    "        'Chain-of-Thought': np.mean([r['cot_complexity']['flesch_kincaid'] - r['original_complexity']['flesch_kincaid'] for r in results]),\n",
    "        'Tree-of-Thought': np.mean([r['tot_complexity']['flesch_kincaid'] - r['original_complexity']['flesch_kincaid'] for r in results])\n",
    "    }\n",
    "    \n",
    "    # Calculate medical term reduction\n",
    "    term_reduction = {\n",
    "        'Basic': np.mean([r['original_complexity']['medical_terms_pct'] - r['basic_complexity']['medical_terms_pct'] for r in results]),\n",
    "        'In-Context': np.mean([r['original_complexity']['medical_terms_pct'] - r['in_context_complexity']['medical_terms_pct'] for r in results]),\n",
    "        'Chain-of-Thought': np.mean([r['original_complexity']['medical_terms_pct'] - r['cot_complexity']['medical_terms_pct'] for r in results]),\n",
    "        'Tree-of-Thought': np.mean([r['original_complexity']['medical_terms_pct'] - r['tot_complexity']['medical_terms_pct'] for r in results])\n",
    "    }\n",
    "    \n",
    "    # Create a summary table\n",
    "    summary = pd.DataFrame({\n",
    "        'Method': ['Basic', 'In-Context', 'Chain-of-Thought', 'Tree-of-Thought'],\n",
    "        'Avg. Readability Improvement': [avg_improvements['Basic'], avg_improvements['In-Context'], \n",
    "                                          avg_improvements['Chain-of-Thought'], avg_improvements['Tree-of-Thought']],\n",
    "        'Avg. Medical Term Reduction (%)': [term_reduction['Basic'], term_reduction['In-Context'], \n",
    "                                             term_reduction['Chain-of-Thought'], term_reduction['Tree-of-Thought']]\n",
    "    })\n",
    "    \n",
    "    print(\"Summary of Method Performance:\")\n",
    "    print(summary)\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    methods = summary['Method']\n",
    "    x = np.arange(len(methods))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width/2, summary['Avg. Readability Improvement'], width, label='Readability Improvement')\n",
    "    ax.bar(x + width/2, summary['Avg. Medical Term Reduction (%)'], width, label='Medical Term Reduction (%)')\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(methods)\n",
    "    ax.legend()\n",
    "    ax.set_ylabel('Improvement')\n",
    "    ax.set_title('Performance Comparison of Different Prompting Methods')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('method_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Run evaluation\n",
    "eval_summary = evaluate_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Education Level Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_education_level_adaptation():\n",
    "    \"\"\"Analyze how well each method adapts to different education levels.\"\"\"\n",
    "    # Calculate adaptation scores\n",
    "    adaptations = []\n",
    "    \n",
    "    education_order = {\n",
    "        'elementary': 0,\n",
    "        'high_school': 1,\n",
    "        'college': 2,\n",
    "        'graduate': 3\n",
    "    }\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        education_level = row['education_level']\n",
    "        edu_level_num = education_order[education_level]\n",
    "        \n",
    "        # Get the corresponding result\n",
    "        result = results[idx]\n",
    "        \n",
    "        # Calculate expected readability by education level\n",
    "        # Higher education should have lower adaptation (less simplification)\n",
    "        expected_adaptation = 1.0 - (edu_level_num / 3.0)\n",
    "        \n",
    "        # Calculate actual adaptation\n",
    "        basic_adapt = (result['basic_complexity']['flesch_kincaid'] - result['original_complexity']['flesch_kincaid']) / 100\n",
    "        in_context_adapt = (result['in_context_complexity']['flesch_kincaid'] - result['original_complexity']['flesch_kincaid']) / 100\n",
    "        cot_adapt = (result['cot_complexity']['flesch_kincaid'] - result['original_complexity']['flesch_kincaid']) / 100\n",
    "        tot_adapt = (result['tot_complexity']['flesch_kincaid'] - result['original_complexity']['flesch_kincaid']) / 100\n",
    "        \n",
    "        # Calculate adaptation error (lower is better)\n",
    "        adaptations.append({\n",
    "            'patient_id': row['patient_id'],\n",
    "            'education_level': education_level,\n",
    "            'expected_adaptation': expected_adaptation,\n",
    "            'basic_adapt_error': abs(basic_adapt - expected_adaptation),\n",
    "            'in_context_adapt_error': abs(in_context_adapt - expected_adaptation),\n",
    "            'cot_adapt_error': abs(cot_adapt - expected_adaptation),\n",
    "            'tot_adapt_error': abs(tot_adapt - expected_adaptation)\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    adapt_df = pd.DataFrame(adaptations)\n",
    "    \n",
    "    # Calculate average adaptation error by method\n",
    "    avg_errors = {\n",
    "        'Basic': adapt_df['basic_adapt_error'].mean(),\n",
    "        'In-Context': adapt_df['in_context_adapt_error'].mean(),\n",
    "        'Chain-of-Thought': adapt_df['cot_adapt_error'].mean(),\n",
    "        'Tree-of-Thought': adapt_df['tot_adapt_error'].mean()\n",
    "    }\n",
    "    \n",
    "    print(\"Average Adaptation Error by Method (lower is better):\")\n",
    "    for method, error in avg_errors.items():\n",
    "        print(f\"{method}: {error:.4f}\")\n",
    "    \n",
    "    # Visualize adaptation by education level\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Group by education level\n",
    "    grouped = adapt_df.groupby('education_level').mean()\n",
    "    \n",
    "    # Plot adaptation errors\n",
    "    grouped[['basic_adapt_error', 'in_context_adapt_error', 'cot_adapt_error', 'tot_adapt_error']].plot(\n",
    "        kind='bar', figsize=(12, 6))\n",
    "    plt.title('Adaptation Error by Education Level (Lower is Better)')\n",
    "    plt.ylabel('Adaptation Error')\n",
    "    plt.xlabel('Education Level')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.legend(['Basic', 'In-Context', 'Chain-of-Thought', 'Tree-of-Thought'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('adaptation_by_education.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return avg_errors, adapt_df\n",
    "\n",
    "# Run adaptation analysis\n",
    "adaptation_errors, adaptation_df = analyze_education_level_adaptation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_prompt(medical_note, education_level):\n",
    "    \"\"\"Combine tree-of-thought reasoning with in-context learning for enhanced performance.\"\"\"\n",
    "    examples = {\n",
    "        \"elementary\": [\n",
    "            {\n",
    "                \"note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c 8.2%).\",\n",
    "                \"simplified\": \"You have high blood sugar (Type 2 Diabetes). Your blood test shows your sugar levels have been high for the past few months.\"\n",
    "            },\n",
    "            {\n",
    "                \"note\": \"Exhibits peripheral edema and occasional dyspnea on exertion.\",\n",
    "                \"simplified\": \"Your ankles and feet are swelling with fluid. Sometimes you feel short of breath when you're active.\"\n",
    "            }\n",
    "        ],\n",
    "        \"high_school\": [\n",
    "            {\n",
    "                \"note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c 8.2%).\",\n",
    "                \"simplified\": \"You have Type 2 Diabetes. Your HbA1c test, which measures your average blood sugar over the past 3 months, shows it's high at 8.2%.\"\n",
    "            },\n",
    "            {\n",
    "                \"note\": \"Exhibits peripheral edema and occasional dyspnea on exertion.\",\n",
    "                \"simplified\": \"You have swelling in your legs and feet, and sometimes have trouble breathing when you're physically active.\"\n",
    "            }\n",
    "        ],\n",
    "        \"college\": [\n",
    "            {\n",
    "                \"note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Notes Simplification using LLMs\n",
    "This notebook demonstrates how to use Large Language Models (LLMs) to simplify medical notes\n",
    "for different patient populations, making healthcare information more accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import requests\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Make sure NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function to Measure Text Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_complexity(text):\n",
    "    \"\"\"\n",
    "    Measures text complexity using various metrics:\n",
    "    - Average sentence length\n",
    "    - Average word length\n",
    "    - Percentage of complex medical terms\n",
    "    - Flesch-Kincaid readability score\n",
    "    \"\"\"\n",
    "    if not text or text.strip() == \"\":\n",
    "        return {\n",
    "            \"avg_sentence_length\": 0,\n",
    "            \"avg_word_length\": 0,\n",
    "            \"medical_terms_pct\": 0,\n",
    "            \"flesch_kincaid\": 100\n",
    "        }\n",
    "    \n",
    "    # Tokenize text\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Filter out punctuation\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_sentence_length = len(words) / max(len(sentences), 1)\n",
    "    avg_word_length = sum(len(word) for word in words) / max(len(words), 1)\n",
    "    \n",
    "    # Simple list of complex medical terms (this would be expanded in a real application)\n",
    "    medical_terms = [\"hypertension\", \"myocardial\", \"infarction\", \"hyperlipidemia\", \n",
    "                    \"atherosclerosis\", \"dyspnea\", \"arrhythmia\", \"tachycardia\", \n",
    "                    \"bradycardia\", \"nephropathy\", \"neuropathy\", \"retinopathy\"]\n",
    "    \n",
    "    medical_terms_count = sum(1 for word in words if word.lower() in medical_terms)\n",
    "    medical_terms_pct = (medical_terms_count / max(len(words), 1)) * 100\n",
    "    \n",
    "    # Calculate Flesch-Kincaid readability score (simplified version)\n",
    "    # 206.835 - 1.015 * (words/sentences) - 84.6 * (syllables/words)\n",
    "    # For simplicity, we'll estimate syllables based on word length\n",
    "    total_syllables = sum(max(1, len(word) // 3) for word in words)\n",
    "    flesch_kincaid = 206.835 - 1.015 * avg_sentence_length - 84.6 * (total_syllables / max(len(words), 1))\n",
    "    flesch_kincaid = max(0, min(100, flesch_kincaid))  # Clamp to [0, 100]\n",
    "    \n",
    "    return {\n",
    "        \"avg_sentence_length\": avg_sentence_length,\n",
    "        \"avg_word_length\": avg_word_length,\n",
    "        \"medical_terms_pct\": medical_terms_pct,\n",
    "        \"flesch_kincaid\": flesch_kincaid\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Synthetic Medical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(filename='synthetic_medical_notes.json'):\n",
    "    \"\"\"\n",
    "    Load sample synthetic medical notes.\n",
    "    If file doesn't exist, create synthetic data.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        # Create synthetic data if file doesn't exist\n",
    "        synthetic_data = [\n",
    "            {\n",
    "                \"patient_id\": \"P001\",\n",
    "                \"age\": 65,\n",
    "                \"education_level\": \"high_school\",\n",
    "                \"medical_note\": \"Patient presents with Stage 2 hypertension (BP 162/94). History of myocardial infarction 3 years ago. Currently on amlodipine 10mg daily and atorvastatin 40mg daily. Exhibits peripheral edema and occasional dyspnea on exertion. ECG shows left ventricular hypertrophy. Recommend DASH diet, sodium restriction, and daily aerobic exercise for 30 minutes.\"\n",
    "            },\n",
    "            {\n",
    "                \"patient_id\": \"P002\",\n",
    "                \"age\": 72,\n",
    "                \"education_level\": \"elementary\",\n",
    "                \"medical_note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c 8.2%). Presents with polyuria, polydipsia, and unexplained weight loss of 10 pounds over 3 months. Fasting plasma glucose 182 mg/dL. Evidence of early diabetic nephropathy with microalbuminuria. Starting metformin 500mg BID, titrating to 1000mg BID over 4 weeks. Referral to diabetic education program and nutritionist.\"\n",
    "            },\n",
    "            {\n",
    "                \"patient_id\": \"P003\",\n",
    "                \"age\": 45,\n",
    "                \"education_level\": \"graduate\",\n",
    "                \"medical_note\": \"Patient exhibits acute bronchitis with purulent sputum production and persistent cough for 10 days. Afebrile, with mild wheezing on expiration. No signs of pneumonia on chest X-ray. CBC shows slight leukocytosis. Prescribed azithromycin 500mg day 1, then 250mg daily for 4 days. Recommended increased fluid intake and rest. Follow up if symptoms persist beyond 14 days.\"\n",
    "            },\n",
    "            {\n",
    "                \"patient_id\": \"P004\",\n",
    "                \"age\": 58,\n",
    "                \"education_level\": \"high_school\",\n",
    "                \"medical_note\": \"Patient presenting with symptoms consistent with GERD, including retrosternal burning pain exacerbated by recumbency and large meals. Upper endoscopy reveals Grade B esophagitis per LA classification. H. pylori test negative. Initiating PPI therapy with omeprazole 40mg daily before breakfast. Lifestyle modifications discussed including elevation of head of bed, weight loss, and avoiding trigger foods.\"\n",
    "            },\n",
    "            {\n",
    "                \"patient_id\": \"P005\",\n",
    "                \"age\": 33,\n",
    "                \"education_level\": \"college\",\n",
    "                \"medical_note\": \"Patient presents with migraine without aura, characterized by unilateral throbbing headache, photophobia, phonophobia, and nausea. Headache frequency of 3-4 episodes monthly, each lasting 12-24 hours. Triggers include stress and irregular sleep. Neurological examination unremarkable. Prescribed sumatriptan 50mg PRN for acute attacks and recommended migraine diary to identify patterns and triggers.\"\n",
    "            }\n",
    "        ]\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(synthetic_data, f, indent=2)\n",
    "        return synthetic_data\n",
    "\n",
    "# Load the data\n",
    "sample_data = load_sample_data()\n",
    "df = pd.DataFrame(sample_data)\n",
    "print(f\"Loaded {len(df)} synthetic medical notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LLM Prompting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_prompt(medical_note):\n",
    "    \"\"\"\n",
    "    Basic prompt for medical note simplification.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please simplify the following medical note for a patient:\n",
    "    \n",
    "    {medical_note}\n",
    "    \n",
    "    Simplified version:\n",
    "    \"\"\"\n",
    "    \n",
    "    # In a real implementation, this would call an LLM API\n",
    "    # For this example, we'll simulate a response\n",
    "    return simulate_llm_response(prompt, method=\"basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_context_learning_prompt(medical_note, education_level):\n",
    "    \"\"\"\n",
    "    In-context learning prompt with examples for specific education levels.\n",
    "    \"\"\"\n",
    "    examples = {\n",
    "        \"elementary\": [\n",
    "            {\n",
    "                \"note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c 8.2%).\",\n",
    "                \"simplified\": \"You have high blood sugar (Type 2 Diabetes). Your blood test shows your sugar levels have been high for the past few months.\"\n",
    "            },\n",
    "            {\n",
    "                \"note\": \"Exhibits peripheral edema and occasional dyspnea on exertion.\",\n",
    "                \"simplified\": \"Your ankles and feet are swelling with fluid. Sometimes you feel short of breath when you're active.\"\n",
    "            }\n",
    "        ],\n",
    "        \"high_school\": [\n",
    "            {\n",
    "                \"note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c 8.2%).\",\n",
    "                \"simplified\": \"You have Type 2 Diabetes. Your HbA1c test, which measures your average blood sugar over the past 3 months, shows it's high at 8.2%.\"\n",
    "            },\n",
    "            {\n",
    "                \"note\": \"Exhibits peripheral edema and occasional dyspnea on exertion.\",\n",
    "                \"simplified\": \"You have swelling in your legs and feet, and sometimes have trouble breathing when you're physically active.\"\n",
    "            }\n",
    "        ],\n",
    "        \"college\": [\n",
    "            {\n",
    "                \"note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c 8.2%).\",\n",
    "                \"simplified\": \"You have Type 2 Diabetes with an HbA1c of 8.2%, indicating poor glycemic control over the past 3 months.\"\n",
    "            },\n",
    "            {\n",
    "                \"note\": \"Exhibits peripheral edema and occasional dyspnea on exertion.\",\n",
    "                \"simplified\": \"You're experiencing fluid retention in your extremities and shortness of breath during physical activity.\"\n",
    "            }\n",
    "        ],\n",
    "        \"graduate\": [\n",
    "            {\n",
    "                \"note\": \"Patient diagnosed with Type 2 Diabetes Mellitus (HbA1c 8.2%).\",\n",
    "                \"simplified\": \"You have Type 2 Diabetes Mellitus with an elevated HbA1c of 8.2%, indicating sustained hyperglycemia over the preceding three months.\"\n",
    "            },\n",
    "            {\n",
    "                \"note\": \"Exhibits peripheral edema and occasional dyspnea on exertion.\",\n",
    "                \"simplified\": \"You're presenting with peripheral edema and intermittent dyspnea upon exertion, suggesting possible cardiovascular or pulmonary etiology.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Default to high_school level if the specified level is not available\n",
    "    if education_level not in examples:\n",
    "        education_level = \"high_school\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Please simplify the following medical note for a patient with {education_level} education level.\n",
    "    \n",
    "    Here are some examples of simplifying medical notes for someone with {education_level} education:\n",
    "    \n",
    "    Original: {examples[education_level][0]['note']}\n",
    "    Simplified: {examples[education_level][0]['simplified']}\n",
    "    \n",
    "    Original: {examples[education_level][1]['note']}\n",
    "    Simplified: {examples[education_level][1]['simplified']}\n",
    "    \n",
    "    Now, please simplify this medical note:\n",
    "    {medical_note}\n",
    "    \n",
    "    Simplified version:\n",
    "    \"\"\"\n",
    "    \n",
    "    return simulate_llm_response(prompt, method=\"in_context\", education_level=education_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_of_thought_prompt(medical_note, education_level):\n",
    "    \"\"\"\n",
    "    Chain-of-thought prompt that asks the LLM to reason through its simplification.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please simplify the following medical note for a patient with {education_level} education level.\n",
    "    \n",
    "    Medical note: {medical_note}\n",
    "    \n",
    "    Let's think through this step by step:\n",
    "    1. First, identify all medical terms that need simplification\n",
    "    2. Determine appropriate replacement words/phrases based on the patient's education level\n",
    "    3. Rewrite the note with simplified terms while preserving all important medical information\n",
    "    4. Check that the simplified note is appropriate for a patient with {education_level} education\n",
    "    \n",
    "    Simplified version:\n",
    "    \"\"\"\n",
    "    \n",
    "    return simulate_llm_response(prompt, method=\"chain_of_thought\", education_level=education_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_of_thought_prompt(medical_note, education_level):\n",
    "    \"\"\"\n",
    "    Tree-of-thought prompt that explores multiple simplification options.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please simplify the following medical note for a patient with {education_level} education level.\n",
    "    \n",
    "    Medical note: {medical_note}\n",
    "    \n",
    "    Let's consider multiple approaches to simplify this note:\n",
    "    \n",
    "    Approach 1: Replace technical terms with common language\n",
    "    - For example, \"hypertension\" becomes \"high blood pressure\"\n",
    "    - How would this approach simplify the entire note?\n",
    "    \n",
    "    Approach 2: Reorganize information by importance\n",
    "    - Start with diagnosis and what it means for the patient\n",
    "    - Follow with treatment plan in simple terms\n",
    "    - End with follow-up instructions\n",
    "    - How would this approach reorganize the note?\n",
    "    \n",
    "    Approach 3: Use metaphors and analogies\n",
    "    - Explain complex medical concepts using everyday comparisons\n",
    "    - How would this approach make the concepts more relatable?\n",
    "    \n",
    "    Now, choose the best elements from each approach to create a final simplified version that is:\n",
    "    - Accurate (contains all critical medical information)\n",
    "    - Understandable (appropriate for {education_level} education level)\n",
    "    - Actionable (patient knows what to do next)\n",
    "    \n",
    "    Final simplified version:\n",
    "    \"\"\"\n",
    "    \n",
    "    return simulate_llm_response(prompt, method=\"tree_of_thought\", education_level=education_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_llm_response(prompt, method, education_level=None):\n",
    "    \"\"\"\n",
    "    Simulates an LLM response. \n",
    "    In a real implementation, this would call an actual LLM API.\n",
    "    \"\"\"\n",
    "    # Extract the medical note from the prompt\n",
    "    medical_note = re.search(r\"Medical note: (.*?)(?:\\n|Let's)\", prompt, re.DOTALL)\n",
    "    if not medical_note:\n",
    "        medical_note = re.search(r\"medical note:\\s*(.*?)(?:\\n|Simplified)\", prompt, re.DOTALL)\n",
    "    \n",
    "    if not medical_note:\n",
    "        return \"Could not parse medical note from prompt.\"\n",
    "    \n",
    "    medical_note = medical_note.group(1).strip()\n",
    "    \n",
    "    # Simple rule-based simplification\n",
    "    simplified = medical_note\n",
    "    \n",
    "    # Replace medical terms with simpler alternatives\n",
    "    replacements = {\n",
    "        \"hypertension\": \"high blood pressure\",\n",
    "        \"myocardial infarction\": \"heart attack\",\n",
    "        \"dyspnea\": \"shortness of breath\",\n",
    "        \"edema\": \"swelling\",\n",
    "        \"amlodipine\": \"blood pressure medicine\",\n",
    "        \"atorvastatin\": \"cholesterol medicine\",\n",
    "        \"peripheral\": \"in your legs and feet\",\n",
    "        \"ECG\": \"heart test\",\n",
    "        \"left ventricular hypertrophy\": \"enlarged heart\",\n",
    "        \"DASH diet\": \"heart-healthy diet\",\n",
    "        \"Type 2 Diabetes Mellitus\": \"type 2 diabetes\",\n",
    "        \"HbA1c\": \"blood sugar test\",\n",
    "        \"polyuria\": \"frequent urination\",\n",
    "        \"polydipsia\": \"feeling very thirsty\",\n",
    "        \"plasma glucose\": \"blood sugar level\",\n",
    "        \"diabetic nephropathy\": \"kidney problems from diabetes\",\n",
    "        \"microalbuminuria\": \"protein in your urine\",\n",
    "        \"metformin\": \"diabetes medicine\",\n",
    "        \"BID\": \"twice daily\",\n",
    "        \"acute bronchitis\": \"chest infection\",\n",
    "        \"purulent sputum\": \"yellow/green mucus\",\n",
    "        \"afebrile\": \"no fever\",\n",
    "        \"wheezing\": \"whistling sound when breathing\",\n",
    "        \"pneumonia\": \"lung infection\",\n",
    "        \"chest X-ray\": \"chest picture\",\n",
    "        \"CBC\": \"blood test\",\n",
    "        \"leukocytosis\": \"high white blood cell count\",\n",
    "        \"azithromycin\": \"antibiotic\",\n",
    "        \"GERD\": \"acid reflux\",\n",
    "        \"retrosternal\": \"behind the breastbone\",\n",
    "        \"recumbency\": \"lying down\",\n",
    "        \"endoscopy\": \"camera test\",\n",
    "        \"esophagitis\": \"inflammation of the food pipe\",\n",
    "        \"H. pylori\": \"stomach bacteria\",\n",
    "        \"PPI therapy\": \"acid-reducing medication\",\n",
    "        \"omeprazole\": \"acid-reducing medicine\",\n",
    "        \"migraine without aura\": \"migraine headache\",\n",
    "        \"unilateral\": \"one-sided\",\n",
    "        \"photophobia\": \"sensitivity to light\",\n",
    "        \"phonophobia\": \"sensitivity to sound\",\n",
    "        \"neurological examination\": \"nerve and brain test\",\n",
    "        \"sumatriptan\": \"migraine medicine\",\n",
    "        \"PRN\": \"as needed\"\n",
    "    }\n",
    "    \n",
    "    # Adjustments based on education level (if provided)\n",
    "    if education_level == \"elementary\":\n",
    "        for term, replacement in replacements.items():\n",
    "            simplified = simplified.replace(term, replacement)\n",
    "        # Further simplify sentences\n",
    "        simplified = simplified.replace(\". \", \".\\n\")\n",
    "        simplified = re.sub(r'(\\d+)mg', r'\\1 milligrams', simplified)\n",
    "        \n",
    "    elif education_level == \"high_school\":\n",
    "        for term, replacement in replacements.items():\n",
    "            # Keep some terms with explanations\n",
    "            if term in [\"HbA1c\", \"ECG\", \"DASH diet\"]:\n",
    "                simplified = simplified.replace(term, f\"{term} ({replacement})\")\n",
    "            else:\n",
    "                simplified = simplified.replace(term, replacement)\n",
    "    \n",
    "    elif education_level == \"college\":\n",
    "        # Keep more medical terms with some explanations\n",
    "        for term, replacement in replacements.items():\n",
    "            if term in [\"dyspnea\", \"peripheral edema\", \"myocardial infarction\", \"hypertension\"]:\n",
    "                simplified = simplified.replace(term, f\"{term} ({replacement})\")\n",
    "            else:\n",
    "                simplified = simplified.replace(term, replacement)\n",
    "    \n",
    "    elif education_level == \"graduate\":\n",
    "        # Keep most medical terms, only simplify very complex ones\n",
    "        for term, replacement in replacements.items():\n",
    "            if term in [\"microalbuminuria\", \"left ventricular hypertrophy\"]:\n",
    "                simplified = simplified.replace(term, f\"{term} ({replacement})\")\n",
    "\n",
    "    # Adjust based on prompting method\n",
    "    if method == \"basic\":\n",
    "        # Basic prompt just gets the default simplified version\n",
    "        pass\n",
    "        \n",
    "    elif method == \"in_context\":\n",
    "        # In-context learning might have better formatting and clarity\n",
    "        simplified = simplified.replace(\". \", \".\\n\\n\")\n",
    "        simplified = \"WHAT THIS MEANS FOR YOU:\\n\\n\" + simplified\n",
    "        \n",
    "    elif method == \"chain_of_thought\":\n",
    "        # Add explanations and action items\n",
    "        simplified += \"\\n\\nWHAT TO DO NEXT:\\n\"\n",
    "        if \"DASH diet\" in medical_note or \"diet\" in medical_note:\n",
    "            simplified += \"\\n- Follow your recommended diet plan\"\n",
    "        if \"exercise\" in medical_note:\n",
    "            simplified += \"\\n- Make sure to exercise regularly as advised\"\n",
    "        if \"medicine\" in simplified or \"medication\" in simplified:\n",
    "            simplified += \"\\n- Take your medications as prescribed\"\n",
    "        simplified += \"\\n- Contact your doctor if you have questions or new symptoms\"\n",
    "        \n",
    "    elif method == \"tree_of_thought\":\n",
    "        # More structured with headers and bullet points\n",
    "        sections = {\n",
    "            \"YOUR CONDITION:\": [],\n",
    "            \"YOUR TREATMENT PLAN:\": [],\n",
    "            \"WHAT TO WATCH FOR:\": [],\n",
    "            \"NEXT STEPS:\": []\n",
    "        }\n",
    "        \n",
    "        # Populate sections based on content\n",
    "        if \"high blood pressure\" in simplified or \"blood pressure\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You have high blood pressure\")\n",
    "        if \"heart attack\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You had a heart attack in the past\")\n",
    "        if \"diabetes\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You have diabetes\")\n",
    "        if \"infection\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You have an infection\")\n",
    "        if \"acid reflux\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You have acid reflux (heartburn)\")\n",
    "        if \"migraine\" in simplified:\n",
    "            sections[\"YOUR CONDITION:\"].append(\"You get migraine headaches\")\n",
    "            \n",
    "        if \"medicine\" in simplified:\n",
    "            meds = re.findall(r'([a-zA-Z]+) (medicine|medication)', simplified)\n",
    "            for med in meds:\n",
    "                sections[\"YOUR TREATMENT PLAN:\"].append(f\"Take your {med[0]} {med[1]} as prescribed\")\n",
    "        \n",
    "        if \"diet\" in simplified:\n",
    "            sections[\"YOUR TREATMENT PLAN:\"].append(\"Follow the recommended diet plan\")\n",
    "        if \"exercise\" in simplified:\n",
    "            sections[\"YOUR TREATMENT PLAN:\"].append(\"Exercise regularly as recommended\")\n",
    "            \n",
    "        sections[\"NEXT STEPS:\"].append(\"Follow up with your doctor as scheduled\")\n",
    "        sections[\"NEXT STEPS:\"].append(\"Call if your symptoms get worse or you have questions\")\n",
    "        \n",
    "        # Format the results\n",
    "        result = \"\"\n",
    "        for section, items in sections.items():\n",
    "            if items:  # Only include non-empty sections\n",
    "                result += section + \"\\n\"\n",
    "                for item in items:\n",
    "                    result += f\"- {item}\\n\"\n",
    "                result += \"\\n\"\n",
    "                \n",
    "        simplified = result\n",
    "    \n",
    "    elif method == \"combined\":\n",
    "        # Combined approach uses both in-context learning and tree-of-thought\n",
    "        # Structure the content using a tree-of-thought approach\n",
    "        sections = {\n",
    "